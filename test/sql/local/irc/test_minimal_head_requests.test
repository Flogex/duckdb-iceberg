# name: test/sql/local/irc/iceberg_catalog_read.test
# description: test integration with iceberg catalog read
# group: [irc]

require-env ICEBERG_SERVER_AVAILABLE

require avro

require parquet

require iceberg

require httpfs

# Do not ignore 'HTTP' error messages!
set ignore_error_messages

statement ok
pragma enable_logging('HTTP');


statement ok
CREATE SECRET (
    TYPE S3,
    KEY_ID 'admin',
    SECRET 'password',
    ENDPOINT '127.0.0.1:9000',
    URL_STYLE 'path',
    USE_SSL 0
);


statement ok
ATTACH '' AS my_datalake (
    TYPE ICEBERG,
    CLIENT_ID 'admin',
    CLIENT_SECRET 'password',
    ENDPOINT 'http://127.0.0.1:8181'
);

query III
select * from my_datalake.default.table_unpartitioned order by all;
----
2023-03-01	1	a
2023-03-02	2	b
2023-03-03	3	c
2023-03-04	4	d
2023-03-05	5	e
2023-03-06	6	f
2023-03-07	7	g
2023-03-08	8	h
2023-03-09	9	i
2023-03-10	10	j
2023-03-11	11	k
2023-03-12	12	l

query III
select * from my_datalake.default.table_unpartitioned order by all;
----
2023-03-01	1	a
2023-03-02	2	b
2023-03-03	3	c
2023-03-04	4	d
2023-03-05	5	e
2023-03-06	6	f
2023-03-07	7	g
2023-03-08	8	h
2023-03-09	9	i
2023-03-10	10	j
2023-03-11	11	k
2023-03-12	12	l


# 2 head requests to the 2 avro files describing my_datalake.default.table_unpartitioned
# with 2 reads to the table, normally there are 4 head requests.
query I
select count(*) from duckdb_logs_parsed('HTTP') where request.type = 'HEAD';
----
2


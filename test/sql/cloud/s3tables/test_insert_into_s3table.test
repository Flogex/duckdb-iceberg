# name: test/sql/cloud/s3tables/test_insert_into_s3table.test
# description: test integration with iceberg catalog read
# group: [s3tables]

require-env ICEBERG_AWS_REMOTE_AVAILABLE

# require-env AWS_ACCESS_KEY_ID
#
# require-env AWS_SECRET_ACCESS_KEY

require avro

require parquet

require iceberg

require httpfs

require aws

statement ok
CREATE SECRET s1 (
  TYPE S3,
  PROVIDER credential_chain
);

statement ok
attach 'arn:aws:s3tables:us-east-2:840140254803:bucket/iceberg-testing' as s3_catalog (
    TYPE ICEBERG,
    secret s1,
    ENDPOINT_TYPE 'S3_TABLES'
);

query IIII
select * from s3_catalog.test_inserts.basic_insert_test order by id
----
1	Alice	Smith	1990-01-01
2	Bob	Jones	1985-06-15
3	Charlie	Brown	2000-12-31

statement ok
begin transaction;

statement ok
insert into s3_catalog.test_inserts.basic_insert_test select * from VALUES
    (5,
    'mr.duck' ,
    '404 lane' ,
    '2010/06/11'::DATE) t(id, name, address, date);

# # read new data before committing
# query IIII
# select * from s3_catalog.test_inserts.basic_insert_test order by id
# ----
# 1	Alice	Smith	1990-01-01
# 2	Bob	Jones	1985-06-15
# 3	Charlie	Brown	2000-12-31
# 5	mr.duck	404 lane	2010-06-11

statement ok
rollback;

mode skip

# # we see the original data after an abort
# query IIII
# select * from s3_catalog.test_inserts.basic_insert_test order by id
# ----
# 1	Alice	Smith	1990-01-01
# 2	Bob	Jones	1985-06-15
# 3	Charlie	Brown	2000-12-31


# Perform an insert into the same table from two separate transactions

statement ok con1
begin

statement ok con1
insert into s3_catalog.test_inserts.basic_insert_test select * from VALUES
    (8,
    'mr.scroog' ,
    'bitlane' ,
    '2010/06/11'::DATE) t(id, name, address, date);

statement ok con2
begin

statement ok con2
insert into s3_catalog.test_inserts.basic_insert_test select * from VALUES
    (10,
    'duckmane' ,
    'byteway' ,
    '2010/06/11'::DATE) t(id, name, address, date);

statement ok con2
commit

# The second commit failed because both transactions tried to add sequence number: 2
# Invalid Configuration Error: Request to 'http://127.0.0.1:8181/v1/transactions/commit' returned a non-200 status code
statement error
commit
----
TransactionContext Error

mode skip

# Insert multiple times into the same table in the same transaction

statement ok
begin

statement ok
insert into s3_catalog.test_inserts.basic_insert_test select * from VALUES
    (15,
    'mr.scroog' ,
    'bitlane' ,
    '2010/06/11'::DATE) t(id, name, address, date);

statement ok
insert into s3_catalog.test_inserts.basic_insert_test select * from VALUES
    (16,
    'mr.Goose' ,
    'ponder' ,
    '2010/06/11'::DATE) t(id, name, address, date);

statement ok
insert into s3_catalog.test_inserts.basic_insert_test select * from VALUES
    (17,
    'ms.Swas' ,
    'lakeway' ,
    '2010/06/11'::DATE) t(id, name, address, date);

statement ok
commit

# query IIII
# select * from my_datalake.default.insert_test;
# ----


# # Insert into both 'insert_test' and 'insert_all_types' in the same transaction
#
# statement ok
# begin
#
# statement ok
# insert into my_datalake.default.insert_test select
# 	'2020/08/16'::DATE a,
# 	4 b,
# 	'insert 4' c
# ;
#
# statement ok
# INSERT INTO my_datalake.default.insert_all_types
# SELECT
# 	127::TINYINT, -- byte_col (max for TINYINT)
# 	1340::SMALLINT, -- short_col (min for SMALLINT)
# 	2147483647::INT, -- int_col (max for INT)
# 	9223372036854775807::BIGINT, -- long_col (max for BIGINT)
# 	3.14::FLOAT, -- float_col (typical float)
# 	-1.7976931348623157::DOUBLE, -- double_col (min for DOUBLE)
# 	1234567890.12345::DECIMAL(15, 5), -- decimal_col
# 	DATE '2023-12-31' -- date_col
# ;
#
# statement ok
# commit
#
# query III
# select * from my_datalake.default.insert_test;
# ----
# 2010-06-11	42	test
# 2020-08-12	45345	inserted by con1
# 2020-08-13	1	insert 1
# 2020-08-14	2	insert 2
# 2020-08-15	3	insert 3
# 2020-08-16	4	insert 4
#
# query IIIIIIII
# select * from my_datalake.default.insert_all_types;
# ----
# 127	1340	2147483647	9223372036854775807	3.14	-1.7976931348623157	1234567890.12345	2023-12-31

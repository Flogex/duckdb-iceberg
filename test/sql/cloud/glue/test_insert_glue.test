# name: test/sql/cloud/glue/test_insert_glue.test
# description: test integration with iceberg catalog read
# group: [glue]

require-env ICEBERG_AWS_REMOTE_AVAILABLE

# require-env AWS_ACCESS_KEY_ID
#
# require-env AWS_SECRET_ACCESS_KEY

require avro

require parquet

require iceberg

require httpfs

require aws

mode skip

statement ok
CREATE SECRET glue_secret (
    TYPE S3,
    PROVIDER credential_chain,
    CHAIN 'sts',
    ASSUME_ROLE_ARN 'arn:aws:iam::840140254803:role/pyiceberg-etl-role',
    REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
    TYPE ICEBERG,
    ENDPOINT_TYPE 'GLUE'
);

query IIII
select * from my_datalake.test_inserts.basic_insert_test order by id
----
1	Alice	Smith	1990-01-01
2	Bob	Jones	1985-06-15
3	Charlie	Brown	2000-12-31

statement ok
begin transaction;

statement ok
insert into my_datalake.test_inserts.basic_insert_test select * from VALUES
    (5,
    'mr.duck' ,
    '404 lane' ,
    '2010/06/11'::DATE) t(id, name, address, date);

# we can read from the table
query IIII
select * from my_datalake.test_inserts.basic_insert_test order by id
----
1	Alice	Smith	1990-01-01
2	Bob	Jones	1985-06-15
3	Charlie	Brown	2000-12-31
5	mr.duck	404 lane	2010-06-11

statement ok
rollback;

mode skip

# we rollback


# we see the original data
query IIII
select * from s3_catalog.test_inserts.basic_insert_test order by id
----
1	Alice	Smith	1990-01-01
2	Bob	Jones	1985-06-15
3	Charlie	Brown	2000-12-31


mode skip


statement ok
commit;

# Read the new data before committing
query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test

# Commit (to the REST catalog)
statement ok
commit;

# Read the new data after committing
query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test

# Perform an INSERT and ABORT it

statement ok
begin transaction;

# Perform an insert in the transaction
statement ok
insert into my_datalake.default.insert_test select
	'1980/11/25'::DATE a,
	-3434 b,
	'this is a long string' c
;

# Read the new data before committing
query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test
1980-11-25	-3434	this is a long string

statement ok
abort;

query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test

# Perform an insert into the same table from two separate transactions

statement ok con1
begin

statement ok con1
insert into my_datalake.default.insert_test select
	'2020/08/12'::DATE a,
	45345 b,
	'inserted by con1' c
;

statement ok con2
begin

statement ok con2
insert into my_datalake.default.insert_test select
	'2020/08/12'::DATE a,
	45345 b,
	'inserted by con2' c
;

statement ok con1
commit

# The second commit failed because both transactions tried to add sequence number: 2
# Invalid Configuration Error: Request to 'http://127.0.0.1:8181/v1/transactions/commit' returned a non-200 status code
statement error
commit
----
Transaction Error

query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test
2020-08-12	45345	inserted by con1

# Insert multiple times into the same table in the same transaction

statement ok
begin

statement ok
insert into my_datalake.default.insert_test select
	'2020/08/13'::DATE a,
	1 b,
	'insert 1' c
;

statement ok
insert into my_datalake.default.insert_test select
	'2020/08/14'::DATE a,
	2 b,
	'insert 2' c
;

statement ok
insert into my_datalake.default.insert_test select
	'2020/08/15'::DATE a,
	3 b,
	'insert 3' c
;

statement ok
commit

query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test
2020-08-12	45345	inserted by con1
2020-08-13	1	insert 1
2020-08-14	2	insert 2
2020-08-15	3	insert 3

# Insert into both 'insert_test' and 'insert_all_types' in the same transaction

statement ok
begin

statement ok
insert into my_datalake.default.insert_test select
	'2020/08/16'::DATE a,
	4 b,
	'insert 4' c
;

statement ok
INSERT INTO my_datalake.default.insert_all_types
SELECT
	127::TINYINT, -- byte_col (max for TINYINT)
	1340::SMALLINT, -- short_col (min for SMALLINT)
	2147483647::INT, -- int_col (max for INT)
	9223372036854775807::BIGINT, -- long_col (max for BIGINT)
	3.14::FLOAT, -- float_col (typical float)
	-1.7976931348623157::DOUBLE, -- double_col (min for DOUBLE)
	1234567890.12345::DECIMAL(15, 5), -- decimal_col
	DATE '2023-12-31' -- date_col
;

statement ok
commit

query III
select * from my_datalake.default.insert_test;
----
2010-06-11	42	test
2020-08-12	45345	inserted by con1
2020-08-13	1	insert 1
2020-08-14	2	insert 2
2020-08-15	3	insert 3
2020-08-16	4	insert 4

query IIIIIIII
select * from my_datalake.default.insert_all_types;
----
127	1340	2147483647	9223372036854775807	3.14	-1.7976931348623157	1234567890.12345	2023-12-31

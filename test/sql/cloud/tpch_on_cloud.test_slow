# name: test/sql/cloud/iceberg_on_tpch.test
# description: test integration with iceberg catalog read
# group: [iceberg]
# setup creds

# TODO, need to get access to a remote glue catalog merged first
# TODO, also important to make the sf=0.1


mode skip

require httpfs

require avro

require parquet

require iceberg

require aws

require tpch

statement ok
CREATE SECRET glue_secret (
    TYPE S3,
    PROVIDER credential_chain,
    CHAIN 'sts',
    ASSUME_ROLE_ARN 'arn:aws:iam::840140254803:role/pyiceberg-etl-role',
    REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
    TYPE ICEBERG,
    ENDPOINT_TYPE 'GLUE'
);

statement ok
create view customer as select * from my_datalake.myblognamespace.customer;

statement ok
create view lineitem as select * from my_datalake.myblognamespace.lineitem;

statement ok
create view nation as select * from my_datalake.myblognamespace.nation;

statement ok
create view orders as select * from my_datalake.myblognamespace.orders;

statement ok
create view part as select * from my_datalake.myblognamespace.part;

statement ok
create view partsupp as select * from my_datalake.myblognamespace.partsupp;

statement ok
create view region as select * from my_datalake.myblognamespace.region;

statement ok
create view supplier as select * from my_datalake.myblognamespace.supplier;


loop i 1 9

query I
PRAGMA tpch(${i})
----
<FILE>:duckdb/extension/tpch/dbgen/answers/sf1/q0${i}.csv

endloop

loop i 10 23

query I
PRAGMA tpch(${i})
----
<FILE>:duckdb/extension/tpch/dbgen/answers/sf1/q${i}.csv

endloop